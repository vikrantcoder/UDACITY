{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELF-DRIVING CAR: Finding Lane Lines.\n",
    "## Project: Finding Lane Lines on the Road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project is to identify lane lines on the road. Given the test images and videos, end goal was to create a pipeline of code to achive the output as show in example folder [P1_example.mp4](examples/P1_example.mp4). For this project I have used Jupyter notebook to execute \n",
    "the project and you can see [this online](https://classroom.udacity.com/courses/ud1111) course from Udacity to know more about the tools used for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEPS TO FIND LANE LINES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For lane detection on a video, we have to pass some steps that you can see below\n",
    "\n",
    "1. Getting each frame from video\n",
    "2. Making grayscale each frame\n",
    "3. Detecting edges by using Canny Algorithm\n",
    "4. Finding Lane by using Hough Algorithm\n",
    "5. Improving output and making a new video as a result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the project I have created the pipeline of the code, which takes Image as the input and image is passed though the pipeline \n",
    "(Series of algorithms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly we can detect the lane lines on the image by providing few discription on RGB threshold value and the pattern of the lane\n",
    "but the system will not be robust by this. To make the system robust, we have to use the computer vision algorithms. \n",
    "To make the system robust we have to detect the objects by their edges. To get the edges of the object we first convert the image to gray and then we have to compute the gradiant and by doing that we can find the edge by mesuring the level of change in gradient values between the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![canny_image](output_readme/solidWhiteRightcany.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, just the important lines of the image which have strong edges have remained. The main question is, how we can extract straight lines from an image. The Hough Algorithm can answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOUGH TRANSFORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hough transform is a feature extraction technique used in image analysis, computer vision, and digital image processing. The purpose of the technique is to find imperfect instances of objects within a certain class of shapes by a voting procedure. This voting procedure is carried out in a parameter space, from which object candidates are obtained as local maxima in a so-called accumulator space that is explicitly constructed by the algorithm for computing the Hough transform. The classical Hough transform was concerned with the identification of lines in the image, but later the Hough transform has been extended to identifying positions of arbitrary shapes, most commonly circles or ellipses. A line in image space can be represented as a single point in parameter space, or Hough Space. We use this theory for detecting lines in a picture. So for achieving this goal, we should add the result of the Canny Algorithm to Hough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HOUGH TRANSFORM](output_readme/HOUGH_TRANSFORM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hough Algorithm has some parameters which have role key in tuning algorithm fine. You can either put a long time for tuning parameters of algorithm or put an especial mask for eliminating other unuseful areas from the picture. Check the difference between using masked area and just tuning parameters of the Hough Algorithm. In the below images you can see the detected lines as red color.\n",
    "\n",
    "Without Area Selection(unMasked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = np.array([[(0, imshape[0]), (0, 0), (imshape[1], 0), (imshape[1], imshape[0])]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hough_without_mask](output_readme/hough_without_mask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suitable Area Selection(Masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    vertices = np.array([[(0,imshape[0]),(460, 318), (490, 318), (imshape[1],imshape[0])]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hough_with_mask](output_readme/hough_with_mask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can see in the above image that the left lane is not continues and some frames will result as shown in below image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![broken lane](output_readme/solidWhiteRightproblem2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To over come above issue, we have to apply below logic on output of Hough Image.After getting x1,y1,x2,y2 from cv2.HoughLinesP call, we have to average and/or extrapolate the line segments we've detected to map out the full extent of the lane lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extrapolate and find the mean we have to convert the line obtained in Image domain to Hough parameter domain and find the mean of M and B points obtained and derive the lane lines from the mean parameter points obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean of all the lines values\n",
    "    AvgPositiveM = mean(mPositiveValues)\n",
    "    AvgNegitiveM = mean(mNegitiveValues)\n",
    "    AvgLeftB     = mean(bLeftValues)\n",
    "    AvgRightB    = mean(bRightValues)\n",
    "\n",
    "    # use average slopes to generate line using ROI endpoints\n",
    "    if AvgPositiveM != 0:\n",
    "        x1_Left = (y_max - AvgLeftB)/AvgPositiveM\n",
    "        y1_Left = y_max\n",
    "        x2_Left = (y_min - AvgLeftB)/AvgPositiveM\n",
    "        y2_Left = y_min\n",
    "        cv2.line(img, (int(x1_Left), int(y1_Left)), (int(x2_Left), int(y2_Left)), color, thickness) #avg Left Line\n",
    "    if AvgNegitiveM != 0:\n",
    "        x1_Right = (y_max - AvgRightB)/AvgNegitiveM\n",
    "        y1_Right = y_max\n",
    "        x2_Right = (y_min - AvgRightB)/AvgNegitiveM\n",
    "        y2_Right = y_min\n",
    "        # define average left and right lines\n",
    "        cv2.line(img, (int(x1_Right), int(y1_Right)), (int(x2_Right), int(y2_Right)), color, thickness) #avg Right Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    After adding above code in our logic we will get the result as in below image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![solved](output_readme/solidWhiteRightsolved.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above algorithm works fine for videos as well considering videos are series of images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
